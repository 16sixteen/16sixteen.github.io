---
layout:     post
title:      "线性代数之直觉学习"
subtitle:   "线性代数"
date:       2018-10-08 23:12:00
categories: LinearAlgebra
tags:       线性代数
author:     "SixTeen"
---

* TOC
{:toc}

### 如何理解线性代数

如何去理解线性代数是一个很重要的问题。没有理解的数学就是冰冷的公式，抽象的理论，如果没有实际应用的反复记忆，很快就会忘记。这里，把线性代数当做一种具备运动思维的工具（数学在其他学科，实践中经常作为一种工具）去理解，直观的去理解这种工具的几何意义。

### 1. 向量

向量是数学中的一个抽象的名词。在数学中，一个抽象的统称名词往往是所有符合数学定义的向量的集合。它可以是一个箭头，可以是一个带方向和标量的值，可以是一个数据列表（计算机中的vector）。既然这里要以具备运动思维的角度去看，那么，显然把向量看做一种运动更为合适，更为直观。**向量就是一个代表从箭头的起始点，走到箭头终点的一个箭头。**

向量的加法，向量的减法，向量的乘法，在这种运动几何角度看来都非常直观和容易理解。点乘，叉乘在后面会重点了解它们的几何意义。

##### 1.1 基向量

描述一个未知的事物往往需要以已知的知识作为基础。描述一个向量也必须依靠一个我们定义的已知的基向量。

我们最常见的2维基向量就是直角坐标系。这里我们把x轴的一个单位长度作为一个箭头的长度，正方向作为它的箭头方向，记作$$\hat{i}$$。同样的，在y轴上取出一个$$\hat{j}$$。这一个就是我们定义的一个基向量。任何一个2维坐标系中的一个向量都能用我们的基向量，用**线性组合**的方式表示出来：$$\vec{v}$$ = a * $$\hat{i}$$ + b * $$\hat{j}$$。

（也许线性组合这个词缺乏了直观，我们可以固定a，b中的其中一个，得出的就是一条直线。）

##### 1.2 线性变换

变换其实也是一个函数。（1对1，多对1）最重要的，变换是一种有着运动思想的函数。

就像我们用 `f(x) = x` 描述一个函数一样，我们可以用变换之后的$$\hat{i}$$，$$\hat{j}$$的落点来描述变换。

假设一个变换结束之后，$$\hat{i}$$落在了$$\begin{bmatrix}1\\2\end{bmatrix}$$，$$\hat{j}$$落在了$$\begin{bmatrix}3\\0\end{bmatrix}$$，那么这个变换可以用一个矩阵（把变换后的$$\hat{i}$$，$$\hat{j}$$放到一起）来描述：$$\begin{bmatrix}1&3\\-2&0\end{bmatrix}$$

现在要求一个$$\begin{bmatrix}1\\1\end{bmatrix}$$经过同样的变换的结果，简单的使用左乘。（为什么是左乘，因为变换本质是一个函数，显然函数是g(f(x))，是从左边不停添加变换的，所以无论是单个变换，还是多个变换的叠加，都是通过不停的添加左乘来决定变换顺序的）

$$\begin{bmatrix}1&3\\-2&0\end{bmatrix}$$$$\begin{bmatrix}1\\1\end{bmatrix}$$=$$\begin{bmatrix}4\\-2\end{bmatrix}$$

为什么可以这样描述变换呢，因为线性变换是一种空间变换，并且变换之后直线仍然是直线，不会变形，因此，$$\vec{v}$$ = a * $$\hat{i}$$ + b * $$\hat{j}$$，变换后$$\vec{v}$$ = a * 变换后$$\hat{i}$$ + b * 变换后$$\hat{j}$$。所以，我们能从这里推出矩阵的乘法法则，

$$\begin{bmatrix}1&3\\-2&0\end{bmatrix}$$$$\begin{bmatrix}x\\y\end{bmatrix}$$=$$\begin{bmatrix}1\\-2\end{bmatrix}$$ * x + $$\begin{bmatrix}-2\\0\end{bmatrix}$$ * y = $$\begin{bmatrix}1 * x + -2 * y \\-2 * x + 0 * y\end{bmatrix}$$

##### 1.3 复合变换

$$ M_1  M_2 \vec{v} $$ 这个复合变换的执行顺序是和刚刚说到的一样，先进行 $$ M_2 $$ 变换，再进行 $$ M_2 $$ 变换。 它等价于 $$ T \vec{v} $$其中$$ T = M_1 M_2 $$。

### 2. 行列式

行列式是测量 变换对空间的拉伸和压缩 的值。

行列式的表示为det(M) = a (当a等于0时，代表这个变换将维度压缩到了低维， 当a大于0的时候，代表空间变换后仍符合右手定则。)

行列式是测量拉伸和压缩的，因此它的公式能用几何的手段合理的推理出来。

试试思考一下，为什么 $$ det(M_1 M_2) = det(M_1)det(M_2) $$。显然，符合变换对空间的拉伸和压缩是和多次变换对空间的拉伸和压缩是一致的。

##### 2.1. 逆矩阵，列空间，零空间

数学中有一种元素叫做逆元，逆元的作用就是消除另一个元素的作用。在函数中，逆元也叫反函数。在变换中，逆元叫逆矩阵。

有了以上的定义，我们可以知道： $$  M^{-1} M \vec{v} = \vec{v} , M^{-1} M = I , I = \begin{bmatrix}1&0&\cdots\\0&1&\cdots\\\vdots&\vdots&\vdots\end{bmatrix} $$, 其中I是一个什么都不做的矩阵，因为它的$$ \hat{i} \hat{j} ... $$都扔在原来的位置。

有了上面的储备知识，那么来考虑一个方程组: $$ M \vec{x} = \vec{v} $$。现在我们需要求解的不再是变换后的向量，而是已知一个向量经过已知变换后的值，求它变换前的向量。显然，我们可以用一个和M变换完全相反的变换，用$$ \vec{v} $$求出 $$ \vec{x} $$， $$ M^-1 M \vec{x} = M^{-1} \vec{v} \Rightarrow I \vec {x} = M^{-1} \vec{v} $$。

现在还有一个问题，所有的变换在变换之后都能变回原来的样子吗？这里显然不是的。在行列式中有提到过，如果行列式的值为0，那么我们的变换是一个压缩维数的变换，这意味着很多高维的信息在压缩到低维的时候丢失了。另一方面，变换是一个函数，符合1对1，多对1的原则。如果一个变换能将空间的维数扩充，那么显然它会是一个1对多的变换，因为它扩充了信息。

因此，当det(M) = 0 的时候，我们就不能使用逆的方法去求解 $$ \vec{x} $$。 (当det(M) = 0的时候，意味着可能很多的向量会从高维落到低维的 $$ \vec{v} $$ 上， 也可能 $$ \vec{v} $$在已经被压缩的高维空间中，这种情况下解就不存在了) 。

到了现在，我们知道我们的变换可能会压缩我们的空间，在线性代数中，用rank（秩）来描述变换后的空间维数， 用列空间来描述变换后所张成的空间（变换M的列向量就是变换后$$ \hat{i} \hat{j} $$的落点，因此它们张成的空间就是变换后的空间）。在空间压缩的时候，也有很多的向量被压缩到了原点中，这些点的集合称为Null Space或者Kernel。

##### 2.2 非方阵

先观察一个非方阵$$ M_1 $$： $$ \begin{bmatrix} a&b\\c&d\\e&f \end{bmatrix} $$ ，观察这个非方阵，我们可以发现，有$$ \hat{i} \hat{j} $$2个向量，变换后这2个向量的维数变成了3，说明这个非方阵是一个将二维空间变换到三维空间的变换。（之前有说过变换没有办法将维数扩充，注意，这里是将一个二维的平面变换成了一个三维空间中的平面。）

再观察一个非方阵$$ M_2 $$： $$ \begin{bmatrix} a&b&c\\d&e&f \end{bmatrix} $$ ，观察这个非方阵，我们可以发现，有$$ \hat{i} \hat{j} \hat{k} $$3个向量，变换之后只用2维坐标来描述，这说明了这个非方阵变换压缩了空间。

### 3. 点积

##### 3.1 常规理解下的点积

$$ dotProduct(\vec{v}, \vec{w}) = \vec{v} \cdot \vec{w} $$，点乘是$$ \vec{w} $$ 在 $$ \vec{v} $$上的投影长度和 $$ \vec{v} $$ 的长度的乘积。

显然，这个操作看起来是顺序有关的，为什么实际上结果却是和顺序无关的呢？假设$$\mid \vec{w} \mid = \mid \vec{v} \mid$$，显然是顺序无关的。再考虑不相等的情况，$$ \vec{w} 和 \vec{v} $$任意伸缩a,b倍，显然得出的投影也是伸缩了a,b倍，最后结果只不过是乘上了a，b倍。

<!-- ![](/img/linearAlgebra/1.png) ![](/img/linearAlgebra/2.png) -->

<table>
	<tr>
		<td>
			<center>
				<img src="/img/linearAlgebra/1.png">
			</center>
		</td>
		<td>
			<center>
				<img src="/img/linearAlgebra/2.png">
			</center>
		</td> 
	</tr>
</table>

##### 3.2 从线性变换的角度理解点积

求点积的时候，两个横放的向量进行点积，求点积的结果和$$ \begin{bmatrix} a&b \end{bmatrix} \begin{bmatrix} c\\d \end{bmatrix} $$的求结果公式一模一样，所以，我们可以猜想他们之间必然是有联系的。那么，思考一下后面一个结果的线性变换的含义。就是对$$ \vec{v} $$进行一个$$ \begin{bmatrix} a&b \end{bmatrix} $$的线性变换。这个1X2的矩阵，意味着这是一个将2维压缩到一维的线性变换，也就是对应的$$ \vec{w} $$在$$ \vec{v} $$上的投影长度。所以，点积就是将2维平面上的一个向量压缩到一条直线上时，向量在这条直线上的表示。

思考一下，为什么这个线性变换的矩阵刚好是向量的转置？我们的线性变换的矩阵追踪的是$$ \hat{i} ， \hat{j} $$的去向，如下图所示，它们的落点正好就是向量的对应的坐标。

![](/img/linearAlgebra/3.png)

##### 3.3 对偶性（duality）

对偶性是数学中一种美妙的自然的又出乎意料的对应关系。在点积中，就存在着这么一种美妙的对偶性：一个多维空间到一维空间的线性变换的对偶是多维空间中的某个特定的向量。

### 4.叉乘

叉乘又称向量积，是两个向量的一种运算。叉乘最广泛的用途是通过两个三维向量的叉乘，得出一个三维的向量，该向量与这两个向量垂直，并且它的模的大小等于这两个向量围成的四边形的面积，它的方向符合右手定则。（食指，中指指向第一，第二个操作数）

##### 4.1 从线性变换的角度理解叉乘

在前一节的对偶性中，一个向量对应着一个多维空间到一个一维空间的线性变换。在叉乘中，同样利用这样的对偶性，找出叉乘对应的一种线性变换。

整个过程分为3个步骤：
1.根据$$ \vec{v} \vec{w} $$定义一个多维到一维的线性变换
2.找到这个线性变换的对偶向量
3.证明这个对偶向量等价于$$ \vec{v} \times \vec{w} $$

###### 4.1.1.定义f($$ \vec{u} $$)

多维到一维的线性变换，并且叉乘得出的向量结果等于两个向量围成的四边形的面积。这些条件似乎都与det行列式有关，而行列式也是一个从多维变换到一维结果的一个运算，因此我们定义一个函数：

$$f(\vec{u}) = det\left( \begin{bmatrix} x&v_1&w_1\\y&v_2&w_2\\z&v_3&w_3 \end{bmatrix} \right)  (其中\vec{u}=\begin{bmatrix} x\\y\\z \end{bmatrix})  $$ 

###### 4.1.2.找到对应的对偶向量$$ \vec{p} $$

我们可以知道，这个对偶向量符合 $$f(\vec{u}) = det\left( \begin{bmatrix} x&v_1&w_1\\y&v_2&w_2\\z&v_3&w_3 \end{bmatrix} \right) = \begin{bmatrix} p_1&p_2&p_3 \end{bmatrix} \begin{bmatrix} x\\y\\z \end{bmatrix}  $$

###### 4.1.3.等价

现在，理解等式两边各项的含义：
1.行列式得出的是这3个向量所围成的六面体的体积，也就是$$ \vec{v} ，\vec{w} $$所围成的面积与$$ \vec{u} $$在该面的法向量上的分量
2.$$ \vec{u} $$ 在 $$ \vec{p} $$ 上的投影长度和$$ \vec{p} $$ 长度的模

所以，$$ \vec{p} $$的长度就是$$ \vec{v} ，\vec{w} $$所围成的面积，且对于所有的$$ \vec{u} $$都成立，且正负关系一致，所以$$ \vec{p} $$的方向与法向量的反向相同。

### 5.基变换

基变换就是描述向量的基本参照的变换。在前面描述的线性变换中，是不改变基的，得到的新的向量是在原基上的表示。对基进行变换，里面所有的向量的描述都需要按照新的基进行描述。

##### 5.1 基变换后的向量描述

1.A基在B基中，用矩阵表示$$ \hat{i} \hat{j} $$为$$ M_{B \to A} $$。（B基变换成A基）
2.向量$$ \vec{a} $$ 在A基中是$$ \begin{bmatrix} 3\\1 \end{bmatrix} $$
3.向量$$ \vec{a} $$在B基中的表示是$$ M_A \vec{a} $$。

这个逻辑看起来似乎有点奇怪，因为向量$$ \vec{a} $$是用A基表示的，为什么是左乘B基到A基的变换而不是A基到B基的变换呢？其实，我们应该把向量$$ \vec{a} $$换一个角度思考，把这个向量看做是我们误以为是用B基表示的$$ \begin{bmatrix} 3\\1 \end{bmatrix} $$，因此，我们需要校准答案的时候，就是对这个误解向量左乘一个基变换的矩阵，这个时候，获得的就是在A基中是$$ \begin{bmatrix} 3\\1 \end{bmatrix} $$，在B基中的正确表达。也就是说，我们误解了其他人基中的向量，以为是同一个向量，现在需要纠正，就将向量在自己的基中线性变换到和实际上正确的向量的同一个位置。

##### 5.2 基变换后的变换描述

1.T是A基中的一个线性变换
2.要利用T对B基中的一个向量$$ \vec{b} $$进行线性变换

这里，最方便的方法就是获得一个T在B基中的描述，但是，我们先不这样做，而是考虑一个思路：利用5.1中的知识，先将向量$$ \vec{b} $$转换成在A基中的表示，然后左乘线性变换T，最后再转回到B基中。整个过程：

$$ M_{A \to B}TM_{B \to A}\vec{b} $$

从上面的式子，我们可以将左边看做一个复合变换，因此这个就是这个T变换在基变化之后的描述。更常见的，$$ M^{-1}TM $$ 往往代表的是一种非同基的线性变换。（这在图形学中特别常见，世界坐标，摄像机坐标等等不同坐标系的变换）

### 6.特征向量，特征值

$$ M\vec{v} = \lambda \vec{v} $$

从式子上理解，特征向量经过变换后，仍留在原来的直线空间上，只是拉伸压缩了$$ \lambda $$倍（特征值）。

同样的，从式子中，还能看出$$ M \Leftrightarrow \lambda $$, $$ \lambda I = \lambda \begin{bmatrix} 1&0&0\\0&1&0\\0&0&1 \end{bmatrix} $$, $$ (M-\lambda I)\vec{v} = 0 $$, 因为从直线压缩到了原点，所以维度降低了，所以$$ det(M-\lambda I) = 0 $$。

##### 6.1 对角矩阵

1.当一个线性变换，只对基进行缩放，显然，这个线性变换矩阵可以写成一个对角矩阵。

$$ \begin{bmatrix} a&0\\0&b \end{bmatrix} $$

2.进行100次这个线性变换时,

$$ \begin{bmatrix} a&0\\0&b \end{bmatrix} ... \begin{bmatrix} a&0\\0&b \end{bmatrix} = \begin{bmatrix} a^{100}&0\\0&b^{100} \end{bmatrix} $$ (进行了100次缩放)

3.对于一个非对角化的变换，我们可以先转换为某个坐标系下的对角矩阵。（以非线性相关的特征向量为基的坐标系）

### 7.抽象向量空间

向量是一个特例。数学中的线性变换之所以这么难理解，是因为数学中的线性变换是一种抽象。所有符合条件的变换都是数学中的线性变换，是线性变换就符合线性变换的所有特性。

例：把求导数看做一个线性变换，那么它必然可以写成一个矩阵的形式，对于多项式求导，矩阵可以写成：

$$ M = \begin{bmatrix} 0&1&0&0\\0&0&2&0\\0&0&0&3 \end{bmatrix} $$

$$ \frac{d(1+2x+3x^2)}{dx} = \begin{bmatrix} 0&1&0\\0&0&2\\0&0&0 \end{bmatrix} \begin{bmatrix} 1\\2\\3 \end{bmatrix} = \begin{bmatrix} 2\\6\\0 \end{bmatrix} = 2 + 6x^2 $$

同时，因为把求导看做一个线性变换，那么求导也应该符合：

1.$$ L(A+B) = L(A) + L(B) $$

2.$$ L(cA) = cL(A) $$

这些正是求导中的：

1.$$ \frac{d(x^3+x^2)}{dx} = \frac{dx^3}{dx} + \frac{dx^2}{dx} $$

2.$$ \frac{d3x}{dx} = 3\frac{dx}{dx} $$

>所有的这些理解都是通过观看3blue1brown的线性代数合集略有所悟，推荐大家都去观看他的数学科普视频，通过动画，将难以理解的很多知识以直观的直觉展现出来，非常的棒：<br/>[【官方双语/合集】线性代数的本质 - 系列合集](https://www.bilibili.com/video/av6731067)

>FIN 2018.10.08/23.12